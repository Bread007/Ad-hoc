{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\t0d00dh\\01_Projects\\2019\\IDPs\\walmart-realty-ms-case-study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh = pd.read_csv('households.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "trips  = pd.read_csv('trips.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the data for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.  Create matrix to store distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "# approximate radius of earth in km\n",
    "R = 6373.0\n",
    "def cor_distance ((lt1, ln1, lt2, ln2)):  \n",
    "    lat1 = radians(lt1)\n",
    "    lon1 = radians(ln1)\n",
    "    lat2 = radians(lt2)\n",
    "    lon2 = radians(ln2)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c * 0.6213 # km to mile\n",
    "    \n",
    "    return (distance)\n",
    "\n",
    "hh_new = pd.DataFrame()\n",
    "hh_new ['hh_id'] =  hh['hh_id']\n",
    "hh_new['hh_cor'] = zip(hh['home_latitude'],hh['home_longitude'])\n",
    "\n",
    "\n",
    "stores['st_cor'] = zip(stores['Latitude'],stores['Longitude'])\n",
    "vec = pd.DataFrame(stores['st_cor'])\n",
    "\n",
    "# repeat the transpose vectore \n",
    "hh_new = hh_new.merge(pd.concat([vec.T]*len(hh_new),ignore_index=True), left_index=True, right_index=True)\n",
    "\n",
    "hh_store = pd.DataFrame()\n",
    "hh_store['hh_id'] =  hh['hh_id']\n",
    "for i in range(28):\n",
    "    hh_store[str(i)] = hh_new['hh_cor'] + hh_new.iloc[:,2:][i]\n",
    "    \n",
    "hh_store_distance = hh_store.iloc[:,1:].applymap(lambda x: cor_distance(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Rank the distances for each household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Original Ranking\n",
    "hh_store_rank = hh_store_distance.apply(lambda x: x.rank(), axis=1)\n",
    "\n",
    "## Normalized ranking\n",
    "def normalize_rank (n,x):\n",
    "    x1 = (x-1)/(n-1)\n",
    "    return(x1)\n",
    "hh_store_Nrank = hh_store_rank.applymap(lambda x: normalize_rank(28,x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Transform the normalized ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Transform function\n",
    "\n",
    "def trans_rank(p,x): # p is the power, adjustable\n",
    "    x1 = 1-x**p\n",
    "    return(x1)\n",
    "\n",
    "# power = 0.15, 0.125,0.175,0.1\n",
    "\n",
    "hh_store_TsRank = hh_store_Nrank.applymap(lambda x: trans_rank(0.15,x))\n",
    "hh_store_TsRank_1 = hh_store_Nrank.applymap(lambda x: trans_rank(0.125,x))\n",
    "hh_store_TsRank_2 = hh_store_Nrank.applymap(lambda x: trans_rank(0.175,x)) \n",
    "hh_store_TsRank_3 = hh_store_Nrank.applymap(lambda x: trans_rank(0.1,x)) \n",
    "\n",
    "\n",
    "# Create long table for each df\n",
    "hh_store_distance['hh_id'] = hh['hh_id']\n",
    "hh_store_rank['hh_id'] = hh['hh_id']\n",
    "hh_store_Nrank['hh_id'] = hh['hh_id']\n",
    "hh_store_TsRank['hh_id'] = hh['hh_id']\n",
    "hh_store_TsRank_1['hh_id'] = hh['hh_id']\n",
    "hh_store_TsRank_2['hh_id'] = hh['hh_id']\n",
    "hh_store_TsRank_3['hh_id'] = hh['hh_id']\n",
    "\n",
    "hhh_store_distance_long = pd.melt(hh_store_distance,id_vars=['hh_id'],var_name='Store_ID', value_name='Distance_Mile')\n",
    "hh_store_rank_long = pd.melt(hh_store_rank,id_vars=['hh_id'],var_name='Store_ID', value_name='Ori_Rank')\n",
    "hh_store_Nrank_long = pd.melt(hh_store_Nrank,id_vars=['hh_id'],var_name='Store_ID', value_name='Norm_Rank')\n",
    "hh_store_TsRank_long = pd.melt(hh_store_TsRank,id_vars=['hh_id'],var_name='Store_ID', value_name='Ts_Rk_.15')\n",
    "hh_store_TsRank_long_1 = pd.melt(hh_store_TsRank_1,id_vars=['hh_id'],var_name='Store_ID', value_name='Ts_Rk_.125')\n",
    "hh_store_TsRank_long_2 = pd.melt(hh_store_TsRank_2,id_vars=['hh_id'],var_name='Store_ID', value_name='Ts_Rk_.175')\n",
    "hh_store_TsRank_long_3 = pd.melt(hh_store_TsRank_3,id_vars=['hh_id'],var_name='Store_ID', value_name='Ts_Rk_.1')\n",
    "\n",
    "# Merge All the dfs, for easy validation\n",
    "\n",
    "df_dis_ranks = pd.merge(hhh_store_distance_long,hh_store_rank_long)\n",
    "df_dis_ranks = pd.merge(df_dis_ranks,hh_store_Nrank_long)\n",
    "df_dis_ranks = pd.merge(df_dis_ranks,hh_store_TsRank_long )\n",
    "df_dis_ranks = pd.merge(df_dis_ranks,hh_store_TsRank_long_1 )\n",
    "df_dis_ranks = pd.merge(df_dis_ranks,hh_store_TsRank_long_2 )\n",
    "df_dis_ranks = pd.merge(df_dis_ranks,hh_store_TsRank_long_3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Calculate Store Visit Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trips['Store_ID'] = trips['store_choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visit_freq = pd.pivot_table(trips,index =['hh_id'], columns=['Store_ID'],values = ['store_choice'],\n",
    "                            aggfunc = 'count')\n",
    "visit_freq = visit_freq.reset_index()\n",
    "visit_freq.columns = ['hh_id' ,\n",
    "                      0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "\n",
    "visit_freq = visit_freq.fillna(0)\n",
    "visit_freq['Total_Visit'] = visit_freq.iloc[:,1:].apply(np.sum,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Visit_Ratio = pd.DataFrame()\n",
    "\n",
    "for i in range(len(visit_freq)):\n",
    "    df = pd.DataFrame(list(visit_freq.iloc[i,1:-1]/visit_freq.iloc[i,-1])).T\n",
    "    Visit_Ratio  = Visit_Ratio.append(df,ignore_index=True)\n",
    "Visit_Ratio['hh_id'] = visit_freq['hh_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the wide table to long table\n",
    "Visit_Ratio_long = pd.melt(Visit_Ratio,id_vars=['hh_id'],var_name='Store_ID', value_name='Visit_Ratio')\n",
    "Visit_Ratio_long['Store_ID'] = Visit_Ratio_long['Store_ID'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.merge(Visit_Ratio_long,df_dis_ranks)\n",
    "stores['Store_ID'] = stores['Store_ID'].apply(lambda x: str(x))\n",
    "\n",
    "df_final = pd.merge(df_final,stores[['Store_ID','Store_Category']],how = 'left', on ='Store_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final['Other'] = (df_final['Store_Category']=='Other').astype(int)\n",
    "df_final['Specialty'] = (df_final['Store_Category']=='Specialty').astype(int)\n",
    "df_final['Walmart Neighborhood Market'] = (df_final['Store_Category']=='Walmart Neighborhood Market').astype(int)\n",
    "df_final['Walmart Supercenter'] = (df_final['Store_Category']=='Walmart Supercenter').astype(int)\n",
    "df_final['Sams Club'] = (df_final['Store_Category']=='Sams Club').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final.to_csv('Store_HH_RK_Type_Long_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_final[df_final['hh_id'] == 0].to_csv('df_final_hh1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ramdomly select 10000 household to train the model\n",
    "import random\n",
    "hh_train = random.sample(range(14150),10000)\n",
    "\n",
    "train_bool = [ i in hh_train for i in df_final['hh_id']]\n",
    "df_train =  df_final[train_bool]\n",
    "\n",
    "test_ix = list(set(df_final.index) - set(df_train.index))\n",
    "df_test = df_final.iloc[test_ix,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df_final['Visit_Ratio']\n",
    "dic1 = {'T1':df_final['Ts_Rk_.1']*df_final['Specialty'],\n",
    " 'T2':df_final['Ts_Rk_.1']*df_final['Walmart Neighborhood Market'],\n",
    " 'T3':df_final['Ts_Rk_.1']*df_final['Walmart Supercenter'],\n",
    " 'T4':df_final['Ts_Rk_.1']*df_final['Sams Club'],    \n",
    "'T5':df_final['Ts_Rk_.1']*df_final['Other']}\n",
    "X1 = pd.DataFrame(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(Y, X1).fit()\n",
    "predictions = model.predict(X1) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic = {'T1':df_train['Ts_Rk_.15']*df_train['Specialty'],\n",
    " 'T2':df_train['Ts_Rk_.15']*df_train['Walmart Neighborhood Market'],\n",
    " 'T3':df_train['Ts_Rk_.15']*df_train['Walmart Supercenter'],\n",
    " 'T4':df_train['Ts_Rk_.15']*df_train['Sams Club'],    \n",
    "'T5':df_train['Ts_Rk_.15']*df_train['Other']}\n",
    "\n",
    "X = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Intercept: \\n', regr.intercept_)\n",
    "print('Coefficients: \\n', regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
