{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_list = [ u'universally',\n",
    " u'understanding',\n",
    " u'uniform',\n",
    " u'unit',\n",
    " u'underlying',\n",
    " u'unlikely',\n",
    " u'unless',\n",
    " u'united',\n",
    " u'units',\n",
    " u'universe',\n",
    " u'internally',\n",
    " u'increasing',\n",
    " u'intake',\n",
    " u'instruct',\n",
    " u'increment',\n",
    " u'initiator',\n",
    " u'individuals',\n",
    " u'inside',\n",
    " u'intent',\n",
    " u'investigation',\n",
    " u'incentives',\n",
    " u'initiate',\n",
    " u'indicate',\n",
    " u'intends',\n",
    " u'instalments',\n",
    " u'inserted',\n",
    " u'interact',\n",
    " u'inter',\n",
    " u'industry',\n",
    " u'investment',\n",
    " u'initiated',\n",
    " u'indicating',\n",
    " u'information',\n",
    " u'ingesting',\n",
    " u'inquires',\n",
    " u'introduction',\n",
    " u'interviewed',\n",
    " u'internal',\n",
    " u'incase',\n",
    " u'indicator',\n",
    " u'instituted',\n",
    " u'incurring',\n",
    " u'incident',\n",
    " u'interface',\n",
    " u'initiation',\n",
    " u'input',\n",
    " u'integral',\n",
    " u'inspects',\n",
    " u'interactivity',\n",
    " u'index',\n",
    " u'involved',\n",
    " u'integrating',\n",
    " u'insists',\n",
    " u'interactions',\n",
    " u'interests',\n",
    " u'interchangeably',\n",
    " u'invited',\n",
    " u'increased',\n",
    " u'increases',\n",
    " u'installment',\n",
    " u'ins',\n",
    " u'integrity',\n",
    " u'indicated',\n",
    " u'indicates',\n",
    " u'interview',\n",
    " u'innovative',\n",
    " u'incorporated',\n",
    " u'insulated',\n",
    " u'involving',\n",
    " u'independent',\n",
    " u'interim',\n",
    " u'instructional',\n",
    " u'incidents',\n",
    " u'introduce',\n",
    "\n",
    " u'installation',\n",
    " u'informed',\n",
    " u'inquiry',\n",
    " u'investigated',\n",
    " u'intend',\n",
    " u'inclusion',\n",
    " u'involvement',\n",
    " u'investing',\n",
    " u'inducted',\n",
    " u'instructing',\n",
    " u'injection',\n",
    " u'info',\n",
    " u'interventions',\n",
    " u'independently',\n",
    " u'inspection',\n",
    " u'interdepartmental',\n",
    " u'incremental',\n",
    " u'including',\n",
    " u'instance',\n",
    " u'interpretations',\n",
    " u'instantly',\n",
    " u'inc',\n",
    " u'ingredients',\n",
    " u'involve',\n",
    " u'investigator',\n",
    " u'integrate',\n",
    " u'intervals',\n",
    " u'interruptions',\n",
    " u'incorporating',\n",
    " u'initiative',\n",
    " u'interest',\n",
    " u'invoice',\n",
    " u'intellectual',\n",
    " u'initial',\n",
    " u'inspected',\n",
    " u'influencing',\n",
    " u'international',\n",
    " u'institute',\n",
    " u'insider',\n",
    " u'inputs',\n",
    " u'infrastructure',\n",
    " u'industriesR12',\n",
    " u'investigating',\n",
    " u'intermediary',\n",
    " u'inbox',\n",
    " u'intern',\n",
    " u'include',\n",
    " u'insurance',\n",
    " u'initiatives',\n",
    " u'instances',\n",
    " u'interactive',\n",
    " u'individual',\n",
    " u'interfaces',\n",
    " u'interfaced',\n",
    " u'indication',\n",
    " u'integration',\n",
    " u'intermediaries',\n",
    " u'initiating',\n",
    " u'intensive',\n",
    " u'ingredient',\n",
    " u'invoices',\n",
    " u'invoiced',\n",
    " u'interviewees',\n",
    " u'interaction',\n",
    " u'intermediate',\n",
    " u'incentive',\n",
    " u'indicators',\n",
    " u'inPOS',\n",
    " u'insert',\n",
    " u'introduced',\n",
    " u'incurs',\n",
    " u'inhibit',\n",
    " u'induction',\n",
    " u'injections',\n",
    " u'interpretation',\n",
    " u'ingested',\n",
    " u'inspectors',\n",
    " u'incur',\n",
    " u'institution',\n",
    " u'interviewing',\n",
    " u'incumbents',\n",
    " u'investigations',\n",
    " u'installing',\n",
    " u'insights',\n",
    " u'inform',\n",
    " u'individually',\n",
    " u'intended',\n",
    " u'installed',\n",
    " u'inclusions',\n",
    " u'indirect',\n",
    " u'insight',\n",
    " u'inspect',\n",
    " u'informing',\n",
    " u'interfacing',\n",
    " u'includes',\n",
    " u'included',\n",
    " u'invest',\n",
    " u'incorporate',\n",
    " u'induct',\n",
    " u'invoicing',\n",
    " u'inquiries',\n",
    " u'instructions',\n",
    " u'inherent',\n",
    " u'interviews',\n",
    " u'instruction',\n",
    " u'infrastructures',\n",
    " u'investigate',\n",
    " u'initially',\n",
    " u'inactive',\n",
    " u'incidental',\n",
    " u'intense',\n",
    " u'inventories',\n",
    " u'income',\n",
    " u'intentional',\n",
    " u'instead',\n",
    " u'interrupted',\n",
    " u'inspecting',\n",
    " u'investor',\n",
    " u'integrated',\n",
    " u'inbound',\n",
    " u'inconsistencies4',\n",
    " u'incl',\n",
    " u'indefinite',\n",
    " u'inherently',\n",
    " u'incurred',\n",
    " u'intentionally',\n",
    " u'explained',\n",
    " u'expiring',\n",
    " u'example',\n",
    " u'exposing',\n",
    " u'extend',\n",
    " u'extent',\n",
    " u'extraction',\n",
    " u'exploitable',\n",
    " u'exposition',\n",
    " u'exist',\n",
    " u'excl',\n",
    " u'exact',\n",
    " u'exitFN1',\n",
    " u'expensing',\n",
    " u'expenditures',\n",
    " u'explaining',\n",
    " u'exit',\n",
    " u'externally',\n",
    " u'expedition',\n",
    " u'experience',\n",
    " u'executable',\n",
    " u'exclusions',\n",
    " u'exhibited',\n",
    " u'expanded',\n",
    " u'execution',\n",
    " u'exposes',\n",
    " u'existing',\n",
    " u'expeditious',\n",
    " u'experiencing',\n",
    " u'expressed',\n",
    " u'exchanged',\n",
    " u'exposure',\n",
    " u'explanation',\n",
    " u'extending',\n",
    " u'explanations',\n",
    " u'exited',\n",
    " u'expertise',\n",
    " u'exiting',\n",
    " u'explicit',\n",
    " u'extract',\n",
    " u'ex',\n",
    " u'external',\n",
    " u'exposed',\n",
    " u'expecting',\n",
    " u'experienced',\n",
    " u'experiences',\n",
    " u'exits',\n",
    " u'explainexplained',\n",
    " u'expenditure',\n",
    " u'examined',\n",
    " u'expansion',\n",
    " u'expose',\n",
    " u'exposures',\n",
    " u'extracting',\n",
    " u'exports',\n",
    " u'excel',\n",
    " u'exported',\n",
    " u'excellence',\n",
    " u'exploit',\n",
    " u'examine',\n",
    " u'expeditiously',\n",
    " u'existence',\n",
    " u'extended',\n",
    " u'extraordinary',\n",
    " u'extracted',\n",
    " u'expensive',\n",
    " u'extensive',\n",
    " u'examples',\n",
    " u'extensions',\n",
    " u'exercises',\n",
    " u'exercise',\n",
    " u'exchange',\n",
    " u'existent',\n",
    " u'extinguishers',\n",
    " u'exists',\n",
    " u'exploited',\n",
    " u'executive',\n",
    " u'expiry',\n",
    " u'excellent',\n",
    " u'executed',\n",
    " u'executes',\n",
    " u'expectations',\n",
    " u'expense',\n",
    " u'expected',\n",
    " u'expenses',\n",
    " u'experts',\n",
    " u'exterior',\n",
    " u'expensed',\n",
    " u'existed',\n",
    " u'exploring',\n",
    " u'explicitly',\n",
    " u'existences',\n",
    " u'except',\n",
    " u'executing',\n",
    " u'extinguisher',\n",
    " u'exec',\n",
    " u'export',\n",
    " u'explore',\n",
    " u'examination',\n",
    " u'execute',\n",
    " u'extension',\n",
    " u'overly',\n",
    " u'understandable',\n",
    " u'understanding',\n",
    " u'undergone',\n",
    " u'underpayment',\n",
    " u'undergo',\n",
    " u'underlying',\n",
    " u'underground',\n",
    " u'undergoing',\n",
    " u'understood',\n",
    " u'understands',\n",
    " u'mission',\n",
    " u'misc',\n",
    " u'miss',\n",
    "u'disjointed',\n",
    " u'disconnect',\n",
    " u'dispensing',\n",
    " u'displays',\n",
    " u'distance',\n",
    " u'distribution',\n",
    " u'discussions',\n",
    " u'discussion',\n",
    " u'discuss',\n",
    " u'discovered',\n",
    " u'dispatch',\n",
    " u'disposals',\n",
    " u'discloses',\n",
    " u'disclosed',\n",
    " u'distinguish',\n",
    " u'disclosure',\n",
    " u'display',\n",
    " u'disposable',\n",
    " u'disciplinary',\n",
    " u'distracted',\n",
    " u'distributed',\n",
    " u'disperse',\n",
    " u'discipline',\n",
    " u'disbursements',\n",
    " u'discounts',\n",
    " u'discoverable',\n",
    " u'dispense',\n",
    " u'disciplines',\n",
    " u'discovery',\n",
    " u'discount',\n",
    " u'displaying',\n",
    " u'dispatched',\n",
    " u'discontinued',\n",
    " u'discussing',\n",
    " u'discharge',\n",
    " u'disposed',\n",
    " u'disposition',\n",
    " u'discover',\n",
    " u'dispensed',\n",
    " u'disposal',\n",
    " u'disclaimer',\n",
    " u'disclose',\n",
    " u'disjoint',\n",
    " u'distributor'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_excel('Word Cloud Exercise.xlsx',sheet_name='Clean Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.columns =[i for i in raw.iloc[8,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = raw.iloc[9:,:].reset_index()\n",
    "raw = raw.fillna('a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_text = raw[['ID','Project Name','Issue','Issue Title','Detail Finding','Issue Locations','Identified Date','Owner Location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "negative_stop_words =[i for i in stop_words if '\\'t'  in i] +['not','no','nor','but','should','could']\n",
    "stop_words_new = [i for i in stop_words if i not in negative_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def token (text):\n",
    "    token = [w.lower() for w in tokenizer.tokenize(text) if not w.lower() in stop_words_new] \n",
    "    token = [i for i in token if not i.isdigit()]\n",
    "    return token \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_text.iloc[:,4] = df_text.iloc[:,4].apply(lambda x: x.replace(\"stock\", \"inventory\"))\n",
    "df_text.iloc[:,4] = df_text.iloc[:,4].apply(lambda x: x.replace(\"stocks\", \"inventory\"))\n",
    "df_text.iloc[:,4] = df_text.iloc[:,4].apply(lambda x: x.replace('inaccuracy', \"incorrect\"))    \n",
    "df_text.iloc[:,4] = df_text.iloc[:,4].apply(lambda x: x.replace('inaccurately', \"incorrect\"))    \n",
    "df_text.iloc[:,4] = df_text.iloc[:,4].apply(lambda x: x.replace('inaccurate', \"incorrect\"))    \n",
    "df_text.iloc[:,4] = df_text.iloc[:,4].apply(lambda x: x.replace('inaccuracies', \"incorrect\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk = df_text.iloc[:,4].apply(lambda x:token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inaccuraci\n",
      "inaccur\n"
     ]
    }
   ],
   "source": [
    " ps = PorterStemmer() \n",
    "print(ps.stem('inaccuracies'))\n",
    "print(ps.stem('inaccurately'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u,\n",
    " u'inaccuracy',\n",
    " u'inaccurate',\n",
    " u'inaccurately',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entire_word_list = []\n",
    "for i in range(len(tk)):\n",
    "    entire_word_list = entire_word_list +tk[i] \n",
    "entire_word_list = set(entire_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_words = []\n",
    "for i in ['dis','un','in','ex','over','under','mis','erro']:\n",
    "    for j in entire_word_list:\n",
    "        if j.startswith(i):\n",
    "            neg_words = neg_words +[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_words_1 = [i for i in neg_words if i not in remove_list ] +['no','not','nor','lack','wrong','should','could','negative','shrink','inventory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df_text['Neg_Word_Count'] = [len(set(tk[i]).intersection(set(neg_words_1))) for i in range(len(tk))]\n",
    "df_text['Neg_Words']= [set(tk[i]).intersection(set(neg_words_1))for i in range(len(tk))]\n",
    "df_text['Neg_Words'] = df_text['Neg_Words'].apply(lambda x: list(x))\n",
    "\n",
    "df_ix = df_text[df_text['Neg_Word_Count']!=0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_text['phrase_2'] = 'na'\n",
    "for i in df_ix:\n",
    "    phase =[]\n",
    "    for j in df_text.loc[i,'Neg_Words']:\n",
    "        list_ix = tk[i].index(j)\n",
    "        phase = phase +[\"_\".join(tk[i][list_ix:list_ix+2])]\n",
    "        \n",
    "    df_text.iat[i,df_text.columns.get_loc('phrase_2')] = phase\n",
    "      \n",
    "        \n",
    "df_text.iloc[:,-1] = df_text.iloc[:,-1].apply(lambda x:\", \".join(x) )\n",
    "        \n",
    "df_text['phrase_3'] = 'na'\n",
    "for i in df_ix:\n",
    "    phase =[]\n",
    "    for j in df_text.loc[i,'Neg_Words']:\n",
    "        list_ix = tk[i].index(j)\n",
    "        phase = phase +[\"_\".join(tk[i][list_ix:list_ix+3])]\n",
    "        \n",
    "    df_text.iat[i,df_text.columns.get_loc('phrase_3')] = phase\n",
    "      \n",
    "        \n",
    "df_text.iloc[:,-1] = df_text.iloc[:,-1].apply(lambda x:\", \".join(x) )\n",
    "       \n",
    "df_text['phrase_more'] = 'na'\n",
    "for i in df_ix:\n",
    "    phase =[]\n",
    "    for j in df_text.loc[i,'Neg_Words']:\n",
    "        list_ix = tk[i].index(j)\n",
    "        phase = phase +[\"_\".join(tk[i][list_ix-1:list_ix+4])]\n",
    "        \n",
    "    df_text.iat[i,df_text.columns.get_loc('phrase_more')] = phase\n",
    "      \n",
    "        \n",
    "df_text.iloc[:,-1] = df_text.iloc[:,-1].apply(lambda x:\", \".join(x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "tk_1 = df_text.iloc[:,3].apply(lambda x:token(x))\n",
    "\n",
    "df_text['Neg_Word_Count_title'] = [len(set(tk_1[i]).intersection(set(neg_words_1))) for i in range(len(tk_1))]\n",
    "df_text['Neg_Words_title']= [set(tk_1[i]).intersection(set(neg_words_1))for i in range(len(tk_1))]\n",
    "df_text['Neg_Words_title'] = df_text['Neg_Words_title'].apply(lambda x: list(x))\n",
    "\n",
    "df_ix = df_text[df_text['Neg_Word_Count']!=0].index\n",
    "\n",
    "\n",
    "df_text['phrase_title_2'] = 'na'\n",
    "for i in df_ix:\n",
    "    phase =[]\n",
    "    for j in df_text.loc[i,'Neg_Words_title']:\n",
    "        list_ix = tk_1[i].index(j)\n",
    "        phase = phase +[\"_\".join(tk_1[i][list_ix:list_ix+2])]\n",
    "        \n",
    "    df_text.iat[i,df_text.columns.get_loc('phrase_title_2')] = phase\n",
    "      \n",
    "        \n",
    "df_text.iloc[:,-1] = df_text.iloc[:,-1].apply(lambda x:\", \".join(x) )\n",
    "        \n",
    "df_text['phrase_title_3'] = 'na'\n",
    "for i in df_ix:\n",
    "    phase =[]\n",
    "    for j in df_text.loc[i,'Neg_Words_title']:\n",
    "        list_ix = tk_1[i].index(j)\n",
    "        phase = phase +[\"_\".join(tk_1[i][list_ix:list_ix+3])]\n",
    "        \n",
    "    df_text.iat[i,df_text.columns.get_loc('phrase_title_3')] = phase\n",
    "      \n",
    "        \n",
    "df_text.iloc[:,-1] = df_text.iloc[:,-1].apply(lambda x:\", \".join(x) )\n",
    "       \n",
    "df_text['phrase_title_more'] = 'na'\n",
    "for i in df_ix:\n",
    "    phase =[]\n",
    "    for j in df_text.loc[i,'Neg_Words_title']:\n",
    "        list_ix = tk_1[i].index(j)\n",
    "        phase = phase +[\"_\".join(tk_1[i][list_ix-1:list_ix+4])]\n",
    "        \n",
    "    df_text.iat[i,df_text.columns.get_loc('phrase_title_more')] = phase\n",
    "      \n",
    "        \n",
    "df_text.iloc[:,-1] = df_text.iloc[:,-1].apply(lambda x:\", \".join(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_text.to_csv('FFU_Phase_new.csv',encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
